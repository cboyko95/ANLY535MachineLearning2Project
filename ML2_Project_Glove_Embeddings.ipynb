{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML2 Project Glove Embeddings.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSh0xSexvEpN",
        "outputId": "d0638429-a0ad-484a-e34e-35c90a155660"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohpfHBrvva2T"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from keras.optimizers import RMSprop\n",
        "import os\n",
        "import pandas as pd\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Flatten, Dense\n",
        "import matplotlib.pyplot as plt \n",
        "from keras import models\n",
        "from keras.layers import SimpleRNN\n",
        "from keras.layers import LSTM\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.models import Sequential"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fnqHHqdvjZA"
      },
      "source": [
        "data = pd.read_csv('/content/gdrive/MyDrive/ML2 Project/Clickbait and Nonclickbait Data.csv')\n",
        "data2 = data.values\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHjGuY4BwTWi"
      },
      "source": [
        "texts = data2[:, 0]\n",
        "labels = data2[:, 1]\n",
        "labels = labels.astype(str).astype('int32')\n",
        "\n",
        "max_features = 10000\n",
        "maxlen = 100\n",
        "training_samples = 22400\n",
        "testing_samples = 9600\n",
        "max_words = 10000\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTU5-5vfwbcj",
        "outputId": "72e38df0-365b-4579-d08f-a5d8c0c92cfd"
      },
      "source": [
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))\n",
        "data = pad_sequences(sequences, maxlen=maxlen)\n",
        "labels = np.asarray(labels)\n",
        "print('Shape of data tensor:', data.shape)\n",
        "print('Shape of label tensor:', labels.shape)\n",
        "indices = np.arange(data.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "data = data[indices]\n",
        "labels = labels[indices]\n",
        "x_train = data[:training_samples]\n",
        "y_train = labels[:training_samples]\n",
        "x_test = data[training_samples: training_samples + testing_samples]\n",
        "y_test = labels[training_samples: training_samples + testing_samples]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 24222 unique tokens.\n",
            "Shape of data tensor: (32000, 100)\n",
            "Shape of label tensor: (32000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XUivf5lwhkQ",
        "outputId": "9165a5bc-df67-4e18-acdf-db7b63084592"
      },
      "source": [
        "glove_dir = '/content/gdrive/MyDrive/ML2 Project'                \n",
        "embeddings_index = {}\n",
        "f = open(os.path.join(glove_dir, 'glove.6B.50d.txt'), encoding=\"utf8\")\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "print('Found %s word vectors.' % len(embeddings_index))   "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTRuilXYwsqS"
      },
      "source": [
        "embedding_dim = 50\n",
        "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    if i < max_words:\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQpZ-YFRw2cV",
        "outputId": "5b3af883-1b16-49e4-d34d-d8e800fc6a92"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(layers.Embedding(max_features, 50, input_length=maxlen))\n",
        "model.add(layers.Conv1D(32, 7, activation='relu'))\n",
        "model.add(layers.MaxPooling1D(5))\n",
        "model.add(layers.Conv1D(32, 7, activation='relu'))\n",
        "model.add(layers.GlobalMaxPooling1D())\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 100, 50)           500000    \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 94, 32)            11232     \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 18, 32)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 12, 32)            7200      \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d (Global (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 518,465\n",
            "Trainable params: 518,465\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckWGVB4W5yKn"
      },
      "source": [
        "model.layers[0].set_weights([embedding_matrix])\n",
        "model.layers[0].trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4_z2-c1xDHF",
        "outputId": "df2ef72a-c1dd-4a87-c1f2-8bf17fe7db67"
      },
      "source": [
        "model.compile(optimizer='adam',loss='binary_crossentropy', metrics=['acc'])\n",
        "history = model.fit(x_train, y_train,epochs=10,batch_size=128,validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "140/140 [==============================] - 44s 7ms/step - loss: 0.4400 - acc: 0.7992 - val_loss: 0.2111 - val_acc: 0.9145\n",
            "Epoch 2/10\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 0.1948 - acc: 0.9190 - val_loss: 0.1897 - val_acc: 0.9250\n",
            "Epoch 3/10\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 0.1551 - acc: 0.9369 - val_loss: 0.1816 - val_acc: 0.9306\n",
            "Epoch 4/10\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 0.1305 - acc: 0.9521 - val_loss: 0.1685 - val_acc: 0.9391\n",
            "Epoch 5/10\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 0.1101 - acc: 0.9599 - val_loss: 0.1679 - val_acc: 0.9384\n",
            "Epoch 6/10\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 0.0972 - acc: 0.9643 - val_loss: 0.1722 - val_acc: 0.9408\n",
            "Epoch 7/10\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.0914 - acc: 0.9650 - val_loss: 0.1743 - val_acc: 0.9435\n",
            "Epoch 8/10\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.0830 - acc: 0.9704 - val_loss: 0.1848 - val_acc: 0.9402\n",
            "Epoch 9/10\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 0.0709 - acc: 0.9737 - val_loss: 0.1956 - val_acc: 0.9404\n",
            "Epoch 10/10\n",
            "140/140 [==============================] - 1s 4ms/step - loss: 0.0652 - acc: 0.9764 - val_loss: 0.1976 - val_acc: 0.9406\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Sb_UWY55v3U",
        "outputId": "3d762d57-9f29-49a2-d349-7e4466f9a235"
      },
      "source": [
        "model2 = Sequential()\n",
        "model2.add(layers.Embedding(max_features, 50, input_length=maxlen))\n",
        "model2.add(layers.Conv1D(32, 25, activation='relu'))\n",
        "model2.add(layers.MaxPooling1D())\n",
        "model2.add(layers.Conv1D(32, 20, activation='relu'))\n",
        "model2.add(layers.MaxPooling1D())\n",
        "model2.add(layers.Conv1D(32, 5, activation='relu'))\n",
        "model2.add(layers.GlobalMaxPooling1D())\n",
        "model2.add(layers.Dense(1, activation='sigmoid'))\n",
        "model2.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_8 (Embedding)      (None, 100, 50)           500000    \n",
            "_________________________________________________________________\n",
            "conv1d_7 (Conv1D)            (None, 76, 32)            40032     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_4 (MaxPooling1 (None, 38, 32)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_8 (Conv1D)            (None, 19, 32)            20512     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_5 (MaxPooling1 (None, 9, 32)             0         \n",
            "_________________________________________________________________\n",
            "conv1d_9 (Conv1D)            (None, 5, 32)             5152      \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_3 (Glob (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 565,729\n",
            "Trainable params: 565,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qufYlSy8fXS",
        "outputId": "90f334d5-ecd9-45d4-9468-aa3a4d38b135"
      },
      "source": [
        "model2.layers[0].set_weights([embedding_matrix])\n",
        "model2.layers[0].trainable = False\n",
        "model2.compile(optimizer='rmsprop',loss='binary_crossentropy', metrics=['acc'])\n",
        "history2 = model2.fit(x_train, y_train,epochs=30,batch_size=64,validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "280/280 [==============================] - 3s 6ms/step - loss: 0.3190 - acc: 0.8624 - val_loss: 0.1563 - val_acc: 0.9400\n",
            "Epoch 2/30\n",
            "280/280 [==============================] - 1s 4ms/step - loss: 0.1444 - acc: 0.9436 - val_loss: 0.1331 - val_acc: 0.9484\n",
            "Epoch 3/30\n",
            "280/280 [==============================] - 1s 4ms/step - loss: 0.1060 - acc: 0.9601 - val_loss: 0.1199 - val_acc: 0.9527\n",
            "Epoch 4/30\n",
            "280/280 [==============================] - 1s 5ms/step - loss: 0.0861 - acc: 0.9682 - val_loss: 0.1176 - val_acc: 0.9563\n",
            "Epoch 5/30\n",
            "280/280 [==============================] - 1s 4ms/step - loss: 0.0635 - acc: 0.9767 - val_loss: 0.1276 - val_acc: 0.9556\n",
            "Epoch 6/30\n",
            "280/280 [==============================] - 1s 4ms/step - loss: 0.0536 - acc: 0.9822 - val_loss: 0.1401 - val_acc: 0.9574\n",
            "Epoch 7/30\n",
            "280/280 [==============================] - 1s 5ms/step - loss: 0.0438 - acc: 0.9851 - val_loss: 0.1511 - val_acc: 0.9538\n",
            "Epoch 8/30\n",
            "280/280 [==============================] - 1s 4ms/step - loss: 0.0339 - acc: 0.9893 - val_loss: 0.2234 - val_acc: 0.9442\n",
            "Epoch 9/30\n",
            "280/280 [==============================] - 1s 4ms/step - loss: 0.0299 - acc: 0.9896 - val_loss: 0.1875 - val_acc: 0.9545\n",
            "Epoch 10/30\n",
            "280/280 [==============================] - 1s 5ms/step - loss: 0.0224 - acc: 0.9924 - val_loss: 0.2048 - val_acc: 0.9522\n",
            "Epoch 11/30\n",
            "280/280 [==============================] - 1s 5ms/step - loss: 0.0185 - acc: 0.9942 - val_loss: 0.3107 - val_acc: 0.9424\n",
            "Epoch 12/30\n",
            "280/280 [==============================] - 1s 5ms/step - loss: 0.0168 - acc: 0.9942 - val_loss: 0.2246 - val_acc: 0.9565\n",
            "Epoch 13/30\n",
            "280/280 [==============================] - 1s 4ms/step - loss: 0.0138 - acc: 0.9960 - val_loss: 0.2604 - val_acc: 0.9533\n",
            "Epoch 14/30\n",
            "280/280 [==============================] - 1s 4ms/step - loss: 0.0139 - acc: 0.9953 - val_loss: 0.3056 - val_acc: 0.9529\n",
            "Epoch 15/30\n",
            "280/280 [==============================] - 1s 5ms/step - loss: 0.0118 - acc: 0.9955 - val_loss: 0.3489 - val_acc: 0.9511\n",
            "Epoch 16/30\n",
            "280/280 [==============================] - 1s 4ms/step - loss: 0.0160 - acc: 0.9953 - val_loss: 0.3321 - val_acc: 0.9529\n",
            "Epoch 17/30\n",
            "280/280 [==============================] - 1s 4ms/step - loss: 0.0119 - acc: 0.9957 - val_loss: 0.3565 - val_acc: 0.9542\n",
            "Epoch 18/30\n",
            "280/280 [==============================] - 1s 4ms/step - loss: 0.0082 - acc: 0.9972 - val_loss: 0.3913 - val_acc: 0.9520\n",
            "Epoch 19/30\n",
            "280/280 [==============================] - 1s 4ms/step - loss: 0.0097 - acc: 0.9968 - val_loss: 0.3846 - val_acc: 0.9540\n",
            "Epoch 20/30\n",
            "280/280 [==============================] - 1s 4ms/step - loss: 0.0104 - acc: 0.9962 - val_loss: 0.4046 - val_acc: 0.9551\n",
            "Epoch 21/30\n",
            "280/280 [==============================] - 1s 5ms/step - loss: 0.0087 - acc: 0.9966 - val_loss: 0.4045 - val_acc: 0.9576\n",
            "Epoch 22/30\n",
            "280/280 [==============================] - 1s 4ms/step - loss: 0.0074 - acc: 0.9968 - val_loss: 0.4881 - val_acc: 0.9527\n",
            "Epoch 23/30\n",
            "280/280 [==============================] - 1s 4ms/step - loss: 0.0100 - acc: 0.9964 - val_loss: 0.4860 - val_acc: 0.9520\n",
            "Epoch 24/30\n",
            "280/280 [==============================] - 1s 4ms/step - loss: 0.0075 - acc: 0.9977 - val_loss: 0.4822 - val_acc: 0.9545\n",
            "Epoch 25/30\n",
            "280/280 [==============================] - 1s 4ms/step - loss: 0.0068 - acc: 0.9979 - val_loss: 0.5189 - val_acc: 0.9522\n",
            "Epoch 26/30\n",
            "280/280 [==============================] - 1s 4ms/step - loss: 0.0073 - acc: 0.9971 - val_loss: 0.5376 - val_acc: 0.9525\n",
            "Epoch 27/30\n",
            "280/280 [==============================] - 1s 4ms/step - loss: 0.0086 - acc: 0.9973 - val_loss: 0.5090 - val_acc: 0.9529\n",
            "Epoch 28/30\n",
            "280/280 [==============================] - 1s 4ms/step - loss: 0.0049 - acc: 0.9981 - val_loss: 0.8097 - val_acc: 0.9393\n",
            "Epoch 29/30\n",
            "280/280 [==============================] - 1s 5ms/step - loss: 0.0172 - acc: 0.9958 - val_loss: 0.5815 - val_acc: 0.9533\n",
            "Epoch 30/30\n",
            "280/280 [==============================] - 1s 4ms/step - loss: 0.0043 - acc: 0.9982 - val_loss: 0.6558 - val_acc: 0.9498\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZcsbhueAwXd",
        "outputId": "5bd588cb-8282-4833-a596-9d57c33b7157"
      },
      "source": [
        "model2.evaluate(x_val, y_val, verbose = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "300/300 [==============================] - 1s 3ms/step - loss: 0.2236 - acc: 0.9541\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.22358077764511108, 0.9540625214576721]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yOcojG8HDwC1",
        "outputId": "ae4048fd-783d-4e0b-afc1-64fddec726d7"
      },
      "source": [
        "model3 = Sequential()\n",
        "model3.add(Embedding(max_features, 50))\n",
        "model3.add(SimpleRNN(32))\n",
        "model3.add(Dense(1, activation='sigmoid'))\n",
        "model3.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_9 (Embedding)      (None, None, 50)          500000    \n",
            "_________________________________________________________________\n",
            "simple_rnn_8 (SimpleRNN)     (None, 32)                2656      \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 502,689\n",
            "Trainable params: 502,689\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7KwpTkyD8N4",
        "outputId": "883a88ca-3b44-4e60-bd2f-bc316140008c"
      },
      "source": [
        "model3.layers[0].set_weights([embedding_matrix])\n",
        "model3.layers[0].trainable = False\n",
        "model3.compile(optimizer='rmsprop',loss='binary_crossentropy', metrics=['acc'])\n",
        "history3 = model3.fit(x_train, y_train,epochs=20,batch_size=64,validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "280/280 [==============================] - 16s 53ms/step - loss: 0.4371 - acc: 0.7857 - val_loss: 0.1910 - val_acc: 0.9306\n",
            "Epoch 2/20\n",
            "280/280 [==============================] - 14s 51ms/step - loss: 0.1865 - acc: 0.9320 - val_loss: 0.1873 - val_acc: 0.9301\n",
            "Epoch 3/20\n",
            "280/280 [==============================] - 14s 50ms/step - loss: 0.1960 - acc: 0.9259 - val_loss: 0.1692 - val_acc: 0.9357\n",
            "Epoch 4/20\n",
            "280/280 [==============================] - 14s 52ms/step - loss: 0.1701 - acc: 0.9337 - val_loss: 0.2317 - val_acc: 0.9078\n",
            "Epoch 5/20\n",
            "280/280 [==============================] - 14s 51ms/step - loss: 0.1948 - acc: 0.9257 - val_loss: 0.1880 - val_acc: 0.9288\n",
            "Epoch 6/20\n",
            "280/280 [==============================] - 15s 52ms/step - loss: 0.1594 - acc: 0.9399 - val_loss: 0.1583 - val_acc: 0.9402\n",
            "Epoch 7/20\n",
            "280/280 [==============================] - 14s 52ms/step - loss: 0.1581 - acc: 0.9388 - val_loss: 0.1408 - val_acc: 0.9460\n",
            "Epoch 8/20\n",
            "280/280 [==============================] - 14s 51ms/step - loss: 0.1410 - acc: 0.9477 - val_loss: 0.1298 - val_acc: 0.9504\n",
            "Epoch 9/20\n",
            "280/280 [==============================] - 14s 51ms/step - loss: 0.1343 - acc: 0.9491 - val_loss: 0.1532 - val_acc: 0.9397\n",
            "Epoch 10/20\n",
            "280/280 [==============================] - 14s 51ms/step - loss: 0.1295 - acc: 0.9515 - val_loss: 0.1232 - val_acc: 0.9536\n",
            "Epoch 11/20\n",
            "280/280 [==============================] - 14s 51ms/step - loss: 0.1375 - acc: 0.9494 - val_loss: 0.1421 - val_acc: 0.9469\n",
            "Epoch 12/20\n",
            "280/280 [==============================] - 14s 51ms/step - loss: 0.1271 - acc: 0.9542 - val_loss: 0.1679 - val_acc: 0.9350\n",
            "Epoch 13/20\n",
            "280/280 [==============================] - 14s 51ms/step - loss: 0.1279 - acc: 0.9505 - val_loss: 0.1347 - val_acc: 0.9509\n",
            "Epoch 14/20\n",
            "280/280 [==============================] - 15s 52ms/step - loss: 0.1109 - acc: 0.9608 - val_loss: 0.1129 - val_acc: 0.9587\n",
            "Epoch 15/20\n",
            "280/280 [==============================] - 14s 51ms/step - loss: 0.0995 - acc: 0.9656 - val_loss: 0.1114 - val_acc: 0.9589\n",
            "Epoch 16/20\n",
            "280/280 [==============================] - 14s 52ms/step - loss: 0.1006 - acc: 0.9625 - val_loss: 0.1330 - val_acc: 0.9504\n",
            "Epoch 17/20\n",
            "280/280 [==============================] - 14s 51ms/step - loss: 0.0912 - acc: 0.9669 - val_loss: 0.1100 - val_acc: 0.9589\n",
            "Epoch 18/20\n",
            "280/280 [==============================] - 14s 51ms/step - loss: 0.0920 - acc: 0.9661 - val_loss: 0.1125 - val_acc: 0.9580\n",
            "Epoch 19/20\n",
            "280/280 [==============================] - 14s 51ms/step - loss: 0.0894 - acc: 0.9668 - val_loss: 0.1056 - val_acc: 0.9600\n",
            "Epoch 20/20\n",
            "280/280 [==============================] - 14s 51ms/step - loss: 0.0861 - acc: 0.9719 - val_loss: 0.1020 - val_acc: 0.9625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIgJbnJ4Jd8m",
        "outputId": "9726a94f-fa33-46e7-926d-511782d6cfb4"
      },
      "source": [
        "model4 = Sequential()\n",
        "model4.add(Embedding(max_features, 50))\n",
        "model4.add(LSTM(32))\n",
        "model4.add(Dense(1, activation='sigmoid'))\n",
        "model4.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, None, 50)          500000    \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 32)                10624     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 510,657\n",
            "Trainable params: 510,657\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHfN6o9qNwJX",
        "outputId": "c64d823d-ac6e-46c3-9d67-40a66176829f"
      },
      "source": [
        "model4.layers[0].set_weights([embedding_matrix])\n",
        "model4.layers[0].trainable = False\n",
        "model4.compile(optimizer='adam',loss='binary_crossentropy', metrics=['acc'])\n",
        "history4 = model4.fit(x_train, y_train,epochs=20,batch_size=64,validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "280/280 [==============================] - 8s 9ms/step - loss: 0.3257 - acc: 0.8682 - val_loss: 0.1374 - val_acc: 0.9480\n",
            "Epoch 2/20\n",
            "280/280 [==============================] - 2s 6ms/step - loss: 0.1279 - acc: 0.9533 - val_loss: 0.1093 - val_acc: 0.9605\n",
            "Epoch 3/20\n",
            "280/280 [==============================] - 2s 6ms/step - loss: 0.1011 - acc: 0.9633 - val_loss: 0.1047 - val_acc: 0.9618\n",
            "Epoch 4/20\n",
            "280/280 [==============================] - 2s 6ms/step - loss: 0.0833 - acc: 0.9695 - val_loss: 0.0933 - val_acc: 0.9665\n",
            "Epoch 5/20\n",
            "280/280 [==============================] - 2s 6ms/step - loss: 0.0749 - acc: 0.9738 - val_loss: 0.0966 - val_acc: 0.9663\n",
            "Epoch 6/20\n",
            "280/280 [==============================] - 2s 6ms/step - loss: 0.0685 - acc: 0.9755 - val_loss: 0.0900 - val_acc: 0.9694\n",
            "Epoch 7/20\n",
            "280/280 [==============================] - 2s 6ms/step - loss: 0.0600 - acc: 0.9808 - val_loss: 0.0868 - val_acc: 0.9699\n",
            "Epoch 8/20\n",
            "280/280 [==============================] - 2s 7ms/step - loss: 0.0587 - acc: 0.9790 - val_loss: 0.0849 - val_acc: 0.9712\n",
            "Epoch 9/20\n",
            "280/280 [==============================] - 2s 6ms/step - loss: 0.0493 - acc: 0.9814 - val_loss: 0.0882 - val_acc: 0.9696\n",
            "Epoch 10/20\n",
            "280/280 [==============================] - 2s 6ms/step - loss: 0.0469 - acc: 0.9839 - val_loss: 0.0856 - val_acc: 0.9703\n",
            "Epoch 11/20\n",
            "280/280 [==============================] - 2s 6ms/step - loss: 0.0471 - acc: 0.9844 - val_loss: 0.0904 - val_acc: 0.9696\n",
            "Epoch 12/20\n",
            "280/280 [==============================] - 2s 6ms/step - loss: 0.0400 - acc: 0.9859 - val_loss: 0.0982 - val_acc: 0.9685\n",
            "Epoch 13/20\n",
            "280/280 [==============================] - 2s 6ms/step - loss: 0.0386 - acc: 0.9876 - val_loss: 0.0911 - val_acc: 0.9721\n",
            "Epoch 14/20\n",
            "280/280 [==============================] - 2s 6ms/step - loss: 0.0323 - acc: 0.9895 - val_loss: 0.0929 - val_acc: 0.9701\n",
            "Epoch 15/20\n",
            "280/280 [==============================] - 2s 6ms/step - loss: 0.0293 - acc: 0.9901 - val_loss: 0.0951 - val_acc: 0.9710\n",
            "Epoch 16/20\n",
            "280/280 [==============================] - 2s 6ms/step - loss: 0.0270 - acc: 0.9911 - val_loss: 0.0958 - val_acc: 0.9694\n",
            "Epoch 17/20\n",
            "280/280 [==============================] - 2s 6ms/step - loss: 0.0286 - acc: 0.9904 - val_loss: 0.1103 - val_acc: 0.9694\n",
            "Epoch 18/20\n",
            "280/280 [==============================] - 2s 6ms/step - loss: 0.0216 - acc: 0.9932 - val_loss: 0.1015 - val_acc: 0.9703\n",
            "Epoch 19/20\n",
            "280/280 [==============================] - 2s 6ms/step - loss: 0.0196 - acc: 0.9937 - val_loss: 0.1107 - val_acc: 0.9701\n",
            "Epoch 20/20\n",
            "280/280 [==============================] - 2s 7ms/step - loss: 0.0198 - acc: 0.9930 - val_loss: 0.1152 - val_acc: 0.9699\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMq3KTGLObUk",
        "outputId": "f25955bb-5eab-4f71-e7ba-feb34bb84ece"
      },
      "source": [
        "model5 = Sequential()\n",
        "model5.add(Embedding(max_features, 50))\n",
        "model5.add(layers.Bidirectional(layers.LSTM(25)))\n",
        "model5.add(Dense(1, activation='sigmoid'))\n",
        "model5.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, None, 50)          500000    \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 50)                15200     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 515,251\n",
            "Trainable params: 515,251\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqlEIZCGOg80",
        "outputId": "08c405cb-3919-4e17-ad62-efd21a9af239"
      },
      "source": [
        "model5.layers[0].set_weights([embedding_matrix])\n",
        "model5.layers[0].trainable = False\n",
        "model5.compile(optimizer='adam',loss='binary_crossentropy', metrics=['acc'])\n",
        "history5 = model5.fit(x_train, y_train,epochs=30,batch_size=64,validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "280/280 [==============================] - 8s 14ms/step - loss: 0.3658 - acc: 0.8773 - val_loss: 0.1421 - val_acc: 0.9471\n",
            "Epoch 2/30\n",
            "280/280 [==============================] - 3s 11ms/step - loss: 0.1337 - acc: 0.9529 - val_loss: 0.1165 - val_acc: 0.9574\n",
            "Epoch 3/30\n",
            "280/280 [==============================] - 3s 11ms/step - loss: 0.1112 - acc: 0.9586 - val_loss: 0.1108 - val_acc: 0.9594\n",
            "Epoch 4/30\n",
            "280/280 [==============================] - 3s 10ms/step - loss: 0.0960 - acc: 0.9659 - val_loss: 0.1041 - val_acc: 0.9612\n",
            "Epoch 5/30\n",
            "280/280 [==============================] - 3s 10ms/step - loss: 0.0863 - acc: 0.9695 - val_loss: 0.0949 - val_acc: 0.9658\n",
            "Epoch 6/30\n",
            "280/280 [==============================] - 3s 10ms/step - loss: 0.0748 - acc: 0.9724 - val_loss: 0.0946 - val_acc: 0.9676\n",
            "Epoch 7/30\n",
            "280/280 [==============================] - 3s 11ms/step - loss: 0.0721 - acc: 0.9751 - val_loss: 0.0972 - val_acc: 0.9643\n",
            "Epoch 8/30\n",
            "280/280 [==============================] - 3s 10ms/step - loss: 0.0647 - acc: 0.9773 - val_loss: 0.0941 - val_acc: 0.9692\n",
            "Epoch 9/30\n",
            "280/280 [==============================] - 3s 11ms/step - loss: 0.0594 - acc: 0.9777 - val_loss: 0.0909 - val_acc: 0.9685\n",
            "Epoch 10/30\n",
            "280/280 [==============================] - 3s 11ms/step - loss: 0.0554 - acc: 0.9809 - val_loss: 0.0918 - val_acc: 0.9667\n",
            "Epoch 11/30\n",
            "280/280 [==============================] - 3s 11ms/step - loss: 0.0552 - acc: 0.9824 - val_loss: 0.0913 - val_acc: 0.9688\n",
            "Epoch 12/30\n",
            "280/280 [==============================] - 3s 10ms/step - loss: 0.0451 - acc: 0.9845 - val_loss: 0.0929 - val_acc: 0.9676\n",
            "Epoch 13/30\n",
            "280/280 [==============================] - 3s 11ms/step - loss: 0.0469 - acc: 0.9822 - val_loss: 0.0936 - val_acc: 0.9676\n",
            "Epoch 14/30\n",
            "280/280 [==============================] - 3s 10ms/step - loss: 0.0462 - acc: 0.9835 - val_loss: 0.0952 - val_acc: 0.9679\n",
            "Epoch 15/30\n",
            "280/280 [==============================] - 3s 10ms/step - loss: 0.0397 - acc: 0.9863 - val_loss: 0.0953 - val_acc: 0.9688\n",
            "Epoch 16/30\n",
            "280/280 [==============================] - 3s 10ms/step - loss: 0.0353 - acc: 0.9878 - val_loss: 0.1003 - val_acc: 0.9676\n",
            "Epoch 17/30\n",
            "280/280 [==============================] - 3s 11ms/step - loss: 0.0367 - acc: 0.9859 - val_loss: 0.1012 - val_acc: 0.9667\n",
            "Epoch 18/30\n",
            "280/280 [==============================] - 3s 10ms/step - loss: 0.0318 - acc: 0.9887 - val_loss: 0.0936 - val_acc: 0.9692\n",
            "Epoch 19/30\n",
            "280/280 [==============================] - 3s 10ms/step - loss: 0.0298 - acc: 0.9899 - val_loss: 0.1047 - val_acc: 0.9679\n",
            "Epoch 20/30\n",
            "280/280 [==============================] - 3s 10ms/step - loss: 0.0254 - acc: 0.9900 - val_loss: 0.1091 - val_acc: 0.9690\n",
            "Epoch 21/30\n",
            "280/280 [==============================] - 3s 11ms/step - loss: 0.0247 - acc: 0.9913 - val_loss: 0.1029 - val_acc: 0.9672\n",
            "Epoch 22/30\n",
            "280/280 [==============================] - 3s 11ms/step - loss: 0.0234 - acc: 0.9924 - val_loss: 0.1172 - val_acc: 0.9674\n",
            "Epoch 23/30\n",
            "280/280 [==============================] - 3s 11ms/step - loss: 0.0225 - acc: 0.9929 - val_loss: 0.1190 - val_acc: 0.9663\n",
            "Epoch 24/30\n",
            "280/280 [==============================] - 3s 11ms/step - loss: 0.0175 - acc: 0.9947 - val_loss: 0.1196 - val_acc: 0.9667\n",
            "Epoch 25/30\n",
            "280/280 [==============================] - 3s 11ms/step - loss: 0.0229 - acc: 0.9922 - val_loss: 0.1214 - val_acc: 0.9663\n",
            "Epoch 26/30\n",
            "280/280 [==============================] - 3s 10ms/step - loss: 0.0178 - acc: 0.9938 - val_loss: 0.1175 - val_acc: 0.9679\n",
            "Epoch 27/30\n",
            "280/280 [==============================] - 3s 11ms/step - loss: 0.0148 - acc: 0.9960 - val_loss: 0.1256 - val_acc: 0.9672\n",
            "Epoch 28/30\n",
            "280/280 [==============================] - 3s 11ms/step - loss: 0.0130 - acc: 0.9965 - val_loss: 0.1330 - val_acc: 0.9685\n",
            "Epoch 29/30\n",
            "280/280 [==============================] - 3s 10ms/step - loss: 0.0104 - acc: 0.9964 - val_loss: 0.1411 - val_acc: 0.9654\n",
            "Epoch 30/30\n",
            "280/280 [==============================] - 3s 10ms/step - loss: 0.0138 - acc: 0.9953 - val_loss: 0.1284 - val_acc: 0.9674\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnxnkfeVPLKL"
      },
      "source": [
        "model6 = Sequential()\n",
        "model6.add(Embedding(max_features, 50))\n",
        "model6.add(layers.Bidirectional(layers.LSTM(100, return_sequences = True)))\n",
        "model6.add(layers.Bidirectional(layers.LSTM(100, return_sequences= True)))\n",
        "model6.add(layers.Bidirectional(layers.LSTM(100)))\n",
        "model6.add(Dense(1, activation='sigmoid'))\n",
        "model6.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayFNZhJmQLs7"
      },
      "source": [
        "model6.layers[0].set_weights([embedding_matrix])\n",
        "model6.layers[0].trainable = False\n",
        "model6.compile(optimizer='adam',loss='binary_crossentropy', metrics=['acc'])\n",
        "history6 = model6.fit(x_train, y_train,epochs=30,batch_size=64,validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZE7_F6zsRqdz",
        "outputId": "8eda7376-24b7-4bfd-e91f-0c5de8d80225"
      },
      "source": [
        "model7 = Sequential()\n",
        "model7.add(Embedding(max_features, 50))\n",
        "model7.add(layers.Bidirectional(layers.LSTM(50, return_sequences = True)))\n",
        "model7.add(Dense(25, activation='relu'))\n",
        "model7.add(Dense(1, activation='sigmoid'))\n",
        "model7.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_7 (Embedding)      (None, None, 50)          500000    \n",
            "_________________________________________________________________\n",
            "bidirectional_13 (Bidirectio (None, None, 100)         40400     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, None, 25)          2525      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, None, 1)           26        \n",
            "=================================================================\n",
            "Total params: 542,951\n",
            "Trainable params: 542,951\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bt7pbbfJT9NP",
        "outputId": "e1c2bca3-6100-4090-c0ee-c7132e04b963"
      },
      "source": [
        "model7.layers[0].set_weights([embedding_matrix])\n",
        "model7.layers[0].trainable = False\n",
        "model7.compile(optimizer='adam',loss='binary_crossentropy', metrics=['acc'])\n",
        "history7 = model7.fit(x_train, y_train,epochs=30,batch_size=64,validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "280/280 [==============================] - 7s 14ms/step - loss: 0.3857 - acc: 0.8279 - val_loss: 0.1569 - val_acc: 0.9414\n",
            "Epoch 2/30\n",
            "280/280 [==============================] - 3s 11ms/step - loss: 0.1533 - acc: 0.9446 - val_loss: 0.1229 - val_acc: 0.9522\n",
            "Epoch 3/30\n",
            "280/280 [==============================] - 3s 11ms/step - loss: 0.1128 - acc: 0.9600 - val_loss: 0.1074 - val_acc: 0.9580\n",
            "Epoch 4/30\n",
            "280/280 [==============================] - 3s 11ms/step - loss: 0.1042 - acc: 0.9634 - val_loss: 0.1108 - val_acc: 0.9587\n",
            "Epoch 5/30\n",
            "280/280 [==============================] - 3s 11ms/step - loss: 0.0921 - acc: 0.9669 - val_loss: 0.0913 - val_acc: 0.9636\n",
            "Epoch 6/30\n",
            "280/280 [==============================] - 3s 11ms/step - loss: 0.0828 - acc: 0.9728 - val_loss: 0.1009 - val_acc: 0.9625\n",
            "Epoch 7/30\n",
            "280/280 [==============================] - 3s 11ms/step - loss: 0.0753 - acc: 0.9727 - val_loss: 0.1101 - val_acc: 0.9675\n",
            "Epoch 8/30\n",
            "280/280 [==============================] - 3s 11ms/step - loss: 0.0768 - acc: 0.9736 - val_loss: 0.0870 - val_acc: 0.9650\n",
            "Epoch 9/30\n",
            "280/280 [==============================] - 3s 11ms/step - loss: 0.0558 - acc: 0.9802 - val_loss: 0.0792 - val_acc: 0.9683\n",
            "Epoch 10/30\n",
            "280/280 [==============================] - 3s 11ms/step - loss: 0.0571 - acc: 0.9794 - val_loss: 0.0884 - val_acc: 0.9697\n",
            "Epoch 11/30\n",
            "280/280 [==============================] - 3s 11ms/step - loss: 0.0523 - acc: 0.9828 - val_loss: 0.1084 - val_acc: 0.9667\n",
            "Epoch 12/30\n",
            "280/280 [==============================] - 3s 11ms/step - loss: 0.0442 - acc: 0.9846 - val_loss: 0.0860 - val_acc: 0.9708\n",
            "Epoch 13/30\n",
            "280/280 [==============================] - 3s 11ms/step - loss: 0.0416 - acc: 0.9862 - val_loss: 0.0813 - val_acc: 0.9697\n",
            "Epoch 14/30\n",
            "280/280 [==============================] - 3s 11ms/step - loss: 0.0422 - acc: 0.9852 - val_loss: 0.0831 - val_acc: 0.9704\n",
            "Epoch 15/30\n",
            "280/280 [==============================] - 3s 11ms/step - loss: 0.0305 - acc: 0.9893 - val_loss: 0.1161 - val_acc: 0.9693\n",
            "Epoch 16/30\n",
            "280/280 [==============================] - 3s 11ms/step - loss: 0.0334 - acc: 0.9888 - val_loss: 0.0799 - val_acc: 0.9718\n",
            "Epoch 17/30\n",
            "280/280 [==============================] - 3s 11ms/step - loss: 0.0281 - acc: 0.9913 - val_loss: 0.0984 - val_acc: 0.9672\n",
            "Epoch 18/30\n",
            "280/280 [==============================] - 3s 11ms/step - loss: 0.0292 - acc: 0.9896 - val_loss: 0.1015 - val_acc: 0.9686\n",
            "Epoch 19/30\n",
            "280/280 [==============================] - 3s 11ms/step - loss: 0.0240 - acc: 0.9921 - val_loss: 0.0895 - val_acc: 0.9703\n",
            "Epoch 20/30\n",
            "280/280 [==============================] - 3s 11ms/step - loss: 0.0245 - acc: 0.9925 - val_loss: 0.1249 - val_acc: 0.9667\n",
            "Epoch 21/30\n",
            "280/280 [==============================] - 3s 11ms/step - loss: 0.0201 - acc: 0.9937 - val_loss: 0.1082 - val_acc: 0.9701\n",
            "Epoch 22/30\n",
            "280/280 [==============================] - 3s 11ms/step - loss: 0.0317 - acc: 0.9905 - val_loss: 0.1001 - val_acc: 0.9717\n",
            "Epoch 23/30\n",
            "280/280 [==============================] - 3s 11ms/step - loss: 0.0249 - acc: 0.9928 - val_loss: 0.1165 - val_acc: 0.9706\n",
            "Epoch 24/30\n",
            "280/280 [==============================] - 3s 11ms/step - loss: 0.0184 - acc: 0.9946 - val_loss: 0.1202 - val_acc: 0.9722\n",
            "Epoch 25/30\n",
            "280/280 [==============================] - 3s 11ms/step - loss: 0.0159 - acc: 0.9953 - val_loss: 0.1169 - val_acc: 0.9711\n",
            "Epoch 26/30\n",
            "280/280 [==============================] - 3s 11ms/step - loss: 0.0122 - acc: 0.9964 - val_loss: 0.1382 - val_acc: 0.9697\n",
            "Epoch 27/30\n",
            "280/280 [==============================] - 3s 11ms/step - loss: 0.0281 - acc: 0.9910 - val_loss: 0.1120 - val_acc: 0.9700\n",
            "Epoch 28/30\n",
            "280/280 [==============================] - 3s 11ms/step - loss: 0.0189 - acc: 0.9941 - val_loss: 0.1305 - val_acc: 0.9702\n",
            "Epoch 29/30\n",
            "280/280 [==============================] - 3s 11ms/step - loss: 0.0243 - acc: 0.9927 - val_loss: 0.1189 - val_acc: 0.9677\n",
            "Epoch 30/30\n",
            "280/280 [==============================] - 3s 11ms/step - loss: 0.0192 - acc: 0.9952 - val_loss: 0.1359 - val_acc: 0.9696\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7N0wo3XBUjXh",
        "outputId": "92872159-3741-409c-a27a-b2ca1d1ef7c8"
      },
      "source": [
        "model8 = Sequential()\n",
        "model8.add(Embedding(max_features, 50))\n",
        "model8.add(layers.Bidirectional(layers.SimpleRNN(32)))\n",
        "model8.add(Dense(1, activation='sigmoid'))\n",
        "model8.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_8 (Embedding)      (None, None, 50)          500000    \n",
            "_________________________________________________________________\n",
            "bidirectional_14 (Bidirectio (None, 64)                5312      \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 505,377\n",
            "Trainable params: 505,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTp6Xvc_VpuF",
        "outputId": "3d307fa0-fa62-48d3-928a-fbb2ed0ff1e2"
      },
      "source": [
        "model8.layers[0].set_weights([embedding_matrix])\n",
        "model8.layers[0].trainable = False\n",
        "model8.compile(optimizer='adam',loss='binary_crossentropy', metrics=['acc'])\n",
        "history8 = model8.fit(x_train, y_train,epochs=30,batch_size=64,validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "280/280 [==============================] - 34s 98ms/step - loss: 0.3440 - acc: 0.8450 - val_loss: 0.2283 - val_acc: 0.9138\n",
            "Epoch 2/30\n",
            "280/280 [==============================] - 27s 95ms/step - loss: 0.1782 - acc: 0.9329 - val_loss: 0.1703 - val_acc: 0.9373\n",
            "Epoch 3/30\n",
            "280/280 [==============================] - 27s 96ms/step - loss: 0.1469 - acc: 0.9459 - val_loss: 0.1473 - val_acc: 0.9451\n",
            "Epoch 4/30\n",
            "280/280 [==============================] - 27s 95ms/step - loss: 0.1433 - acc: 0.9437 - val_loss: 0.1536 - val_acc: 0.9393\n",
            "Epoch 5/30\n",
            "280/280 [==============================] - 26s 94ms/step - loss: 0.1251 - acc: 0.9505 - val_loss: 0.1307 - val_acc: 0.9502\n",
            "Epoch 6/30\n",
            "280/280 [==============================] - 27s 95ms/step - loss: 0.1193 - acc: 0.9536 - val_loss: 0.1248 - val_acc: 0.9520\n",
            "Epoch 7/30\n",
            "280/280 [==============================] - 27s 95ms/step - loss: 0.1113 - acc: 0.9585 - val_loss: 0.1113 - val_acc: 0.9574\n",
            "Epoch 8/30\n",
            "280/280 [==============================] - 27s 96ms/step - loss: 0.1021 - acc: 0.9620 - val_loss: 0.1123 - val_acc: 0.9569\n",
            "Epoch 9/30\n",
            "280/280 [==============================] - 27s 95ms/step - loss: 0.1090 - acc: 0.9594 - val_loss: 0.1051 - val_acc: 0.9616\n",
            "Epoch 10/30\n",
            "280/280 [==============================] - 27s 95ms/step - loss: 0.0876 - acc: 0.9698 - val_loss: 0.0965 - val_acc: 0.9634\n",
            "Epoch 11/30\n",
            "280/280 [==============================] - 27s 95ms/step - loss: 0.0866 - acc: 0.9669 - val_loss: 0.1049 - val_acc: 0.9594\n",
            "Epoch 12/30\n",
            "280/280 [==============================] - 27s 96ms/step - loss: 0.0808 - acc: 0.9701 - val_loss: 0.1208 - val_acc: 0.9554\n",
            "Epoch 13/30\n",
            "280/280 [==============================] - 27s 95ms/step - loss: 0.0924 - acc: 0.9659 - val_loss: 0.1143 - val_acc: 0.9589\n",
            "Epoch 14/30\n",
            "280/280 [==============================] - 27s 95ms/step - loss: 0.0828 - acc: 0.9699 - val_loss: 0.0989 - val_acc: 0.9652\n",
            "Epoch 15/30\n",
            "280/280 [==============================] - 27s 97ms/step - loss: 0.0784 - acc: 0.9731 - val_loss: 0.1119 - val_acc: 0.9571\n",
            "Epoch 16/30\n",
            "280/280 [==============================] - 26s 94ms/step - loss: 0.0682 - acc: 0.9773 - val_loss: 0.1111 - val_acc: 0.9576\n",
            "Epoch 17/30\n",
            "280/280 [==============================] - 26s 94ms/step - loss: 0.0687 - acc: 0.9751 - val_loss: 0.0960 - val_acc: 0.9661\n",
            "Epoch 18/30\n",
            "280/280 [==============================] - 27s 97ms/step - loss: 0.0737 - acc: 0.9742 - val_loss: 0.1097 - val_acc: 0.9596\n",
            "Epoch 19/30\n",
            "280/280 [==============================] - 27s 95ms/step - loss: 0.0611 - acc: 0.9772 - val_loss: 0.0977 - val_acc: 0.9638\n",
            "Epoch 20/30\n",
            "280/280 [==============================] - 27s 96ms/step - loss: 0.0590 - acc: 0.9798 - val_loss: 0.0966 - val_acc: 0.9654\n",
            "Epoch 21/30\n",
            "280/280 [==============================] - 27s 95ms/step - loss: 0.0638 - acc: 0.9778 - val_loss: 0.0951 - val_acc: 0.9665\n",
            "Epoch 22/30\n",
            "280/280 [==============================] - 27s 96ms/step - loss: 0.0593 - acc: 0.9792 - val_loss: 0.0969 - val_acc: 0.9667\n",
            "Epoch 23/30\n",
            "280/280 [==============================] - 27s 96ms/step - loss: 0.0509 - acc: 0.9804 - val_loss: 0.1105 - val_acc: 0.9600\n",
            "Epoch 24/30\n",
            "280/280 [==============================] - 27s 95ms/step - loss: 0.0601 - acc: 0.9794 - val_loss: 0.1001 - val_acc: 0.9643\n",
            "Epoch 25/30\n",
            "280/280 [==============================] - 27s 96ms/step - loss: 0.0509 - acc: 0.9816 - val_loss: 0.0998 - val_acc: 0.9647\n",
            "Epoch 26/30\n",
            "280/280 [==============================] - 27s 95ms/step - loss: 0.0496 - acc: 0.9827 - val_loss: 0.1204 - val_acc: 0.9556\n",
            "Epoch 27/30\n",
            "280/280 [==============================] - 26s 95ms/step - loss: 0.0566 - acc: 0.9796 - val_loss: 0.0973 - val_acc: 0.9634\n",
            "Epoch 28/30\n",
            "280/280 [==============================] - 27s 95ms/step - loss: 0.0439 - acc: 0.9856 - val_loss: 0.0944 - val_acc: 0.9652\n",
            "Epoch 29/30\n",
            "280/280 [==============================] - 27s 95ms/step - loss: 0.0389 - acc: 0.9876 - val_loss: 0.1023 - val_acc: 0.9654\n",
            "Epoch 30/30\n",
            "280/280 [==============================] - 26s 95ms/step - loss: 0.0527 - acc: 0.9821 - val_loss: 0.1559 - val_acc: 0.9429\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFll6iR7Vpzk",
        "outputId": "0023a8ed-77c8-4dd3-c04c-885b38d7fff3"
      },
      "source": [
        "model9 = Sequential()\n",
        "model9.add(Embedding(max_features, 50))\n",
        "model9.add(layers.Bidirectional(layers.SimpleRNN(20, return_sequences= True)))\n",
        "model9.add(layers.Dropout(0.2))\n",
        "model9.add(layers.Bidirectional(layers.SimpleRNN(20, return_sequences= True)))\n",
        "model9.add(Dense(1, activation='sigmoid'))\n",
        "model9.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_10 (Embedding)     (None, None, 50)          500000    \n",
            "_________________________________________________________________\n",
            "bidirectional_9 (Bidirection (None, None, 40)          2840      \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, None, 40)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional_10 (Bidirectio (None, None, 40)          2440      \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, None, 1)           41        \n",
            "=================================================================\n",
            "Total params: 505,321\n",
            "Trainable params: 505,321\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwEaQRSTVp9J"
      },
      "source": [
        "model9.layers[0].set_weights([embedding_matrix])\n",
        "model9.layers[0].trainable = False\n",
        "model9.compile(optimizer='adam',loss='binary_crossentropy', metrics=['acc'])\n",
        "history9 = model9.fit(x_train, y_train,epochs=30,batch_size=64,validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyzn9VXlVqJm",
        "outputId": "8fc4470c-ebcc-4c2e-9622-3b7e77dc354f"
      },
      "source": [
        "model10 = Sequential()\n",
        "model10.add(Embedding(max_features, 50))\n",
        "model10.add(layers.GRU(32, dropout=0.1,recurrent_dropout=0.5,return_sequences=True,))\n",
        "model10.add(layers.GRU(64, activation='relu',dropout=0.1,recurrent_dropout=0.5))\n",
        "model10.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PaNrenYVVqM3",
        "outputId": "a4e18b51-424b-4fb2-b18c-b45a9efe9902"
      },
      "source": [
        "model10.layers[0].set_weights([embedding_matrix])\n",
        "model10.layers[0].trainable = False\n",
        "model10.compile(optimizer='adam',loss='binary_crossentropy', metrics=['acc'])\n",
        "history10 = model10.fit(x_train, y_train,epochs=50,batch_size=1000,validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "18/18 [==============================] - 18s 706ms/step - loss: 0.0685 - acc: 0.9748 - val_loss: 0.0749 - val_acc: 0.9739\n",
            "Epoch 2/50\n",
            "18/18 [==============================] - 11s 624ms/step - loss: 0.0733 - acc: 0.9741 - val_loss: 0.0748 - val_acc: 0.9739\n",
            "Epoch 3/50\n",
            "18/18 [==============================] - 11s 633ms/step - loss: 0.0684 - acc: 0.9738 - val_loss: 0.0741 - val_acc: 0.9739\n",
            "Epoch 4/50\n",
            "18/18 [==============================] - 12s 641ms/step - loss: 0.0676 - acc: 0.9760 - val_loss: 0.0733 - val_acc: 0.9750\n",
            "Epoch 5/50\n",
            "18/18 [==============================] - 11s 625ms/step - loss: 0.0664 - acc: 0.9757 - val_loss: 0.0738 - val_acc: 0.9741\n",
            "Epoch 6/50\n",
            "18/18 [==============================] - 12s 646ms/step - loss: 0.0575 - acc: 0.9780 - val_loss: 0.0733 - val_acc: 0.9730\n",
            "Epoch 7/50\n",
            "18/18 [==============================] - 11s 623ms/step - loss: 0.0609 - acc: 0.9782 - val_loss: 0.0737 - val_acc: 0.9748\n",
            "Epoch 8/50\n",
            "18/18 [==============================] - 11s 623ms/step - loss: 0.0635 - acc: 0.9758 - val_loss: 0.0733 - val_acc: 0.9746\n",
            "Epoch 9/50\n",
            "18/18 [==============================] - 11s 635ms/step - loss: 0.0677 - acc: 0.9760 - val_loss: 0.0731 - val_acc: 0.9743\n",
            "Epoch 10/50\n",
            "18/18 [==============================] - 11s 618ms/step - loss: 0.0609 - acc: 0.9779 - val_loss: 0.0749 - val_acc: 0.9739\n",
            "Epoch 11/50\n",
            "18/18 [==============================] - 11s 623ms/step - loss: 0.0640 - acc: 0.9767 - val_loss: 0.0725 - val_acc: 0.9741\n",
            "Epoch 12/50\n",
            "18/18 [==============================] - 12s 642ms/step - loss: 0.0634 - acc: 0.9765 - val_loss: 0.0744 - val_acc: 0.9739\n",
            "Epoch 13/50\n",
            "18/18 [==============================] - 11s 622ms/step - loss: 0.0577 - acc: 0.9782 - val_loss: 0.0730 - val_acc: 0.9748\n",
            "Epoch 14/50\n",
            "18/18 [==============================] - 11s 636ms/step - loss: 0.0549 - acc: 0.9786 - val_loss: 0.0734 - val_acc: 0.9748\n",
            "Epoch 15/50\n",
            "18/18 [==============================] - 11s 635ms/step - loss: 0.0563 - acc: 0.9784 - val_loss: 0.0780 - val_acc: 0.9741\n",
            "Epoch 16/50\n",
            "18/18 [==============================] - 11s 631ms/step - loss: 0.0588 - acc: 0.9766 - val_loss: 0.0728 - val_acc: 0.9746\n",
            "Epoch 17/50\n",
            "18/18 [==============================] - 11s 620ms/step - loss: 0.0537 - acc: 0.9806 - val_loss: 0.0742 - val_acc: 0.9766\n",
            "Epoch 18/50\n",
            "18/18 [==============================] - 11s 628ms/step - loss: 0.0592 - acc: 0.9785 - val_loss: 0.0743 - val_acc: 0.9752\n",
            "Epoch 19/50\n",
            "18/18 [==============================] - 11s 622ms/step - loss: 0.0557 - acc: 0.9791 - val_loss: 0.0735 - val_acc: 0.9750\n",
            "Epoch 20/50\n",
            " 2/18 [==>...........................] - ETA: 9s - loss: 0.0574 - acc: 0.9782 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-6c01dc8b6488>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel10\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel10\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mhistory10\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel10\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1156\u001b[0m                 _r=1):\n\u001b[1;32m   1157\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUUq90yu550j",
        "outputId": "1e59efa0-ed8e-46bb-d383-5b02445ba1f7"
      },
      "source": [
        "model11 = Sequential()\n",
        "model11.add(Embedding(max_features, 50))\n",
        "model11.add(layers.GRU(30, dropout=0.1,recurrent_dropout=0.5,return_sequences=True))\n",
        "model11.add(layers.GRU(50, activation='relu',dropout=0.1,recurrent_dropout=0.5, return_sequences=True))\n",
        "model11.add(layers.GRU(100, activation='relu',dropout=0.1,recurrent_dropout=0.5))\n",
        "model11.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer gru_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2Kon7SE6MPh"
      },
      "source": [
        "import keras\n",
        "from keras.callbacks import ModelCheckpoint \n",
        "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience= 10) \n",
        "callbacks_list= ModelCheckpoint('Models/Weights-{epoch:03d}--{val_loss:.5f}.hdf5', monitor='val_loss', save_best_only = True) \n",
        "callbacks = [early_stop, callbacks_list] \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1A_BsEJ56fno",
        "outputId": "1ef22a94-51db-4e17-bce6-d44bf322813e"
      },
      "source": [
        "model11.layers[0].set_weights([embedding_matrix])\n",
        "model11.layers[0].trainable = False\n",
        "model11.compile(optimizer='adam',loss='binary_crossentropy', metrics=['acc'])\n",
        "history11 = model11.fit(x_train, y_train,epochs=100,batch_size=1000,validation_split=0.2, callbacks = callbacks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "18/18 [==============================] - 28s 1s/step - loss: 0.6577 - acc: 0.6985 - val_loss: 0.4021 - val_acc: 0.8815\n",
            "Epoch 2/100\n",
            "18/18 [==============================] - 18s 1s/step - loss: 0.3441 - acc: 0.8755 - val_loss: 0.2056 - val_acc: 0.9167\n",
            "Epoch 3/100\n",
            "18/18 [==============================] - 18s 995ms/step - loss: 0.2161 - acc: 0.9166 - val_loss: 0.1690 - val_acc: 0.9321\n",
            "Epoch 4/100\n",
            "18/18 [==============================] - 18s 998ms/step - loss: 0.1780 - acc: 0.9317 - val_loss: 0.1424 - val_acc: 0.9449\n",
            "Epoch 5/100\n",
            "18/18 [==============================] - 18s 998ms/step - loss: 0.1588 - acc: 0.9378 - val_loss: 0.1314 - val_acc: 0.9491\n",
            "Epoch 6/100\n",
            "18/18 [==============================] - 18s 1s/step - loss: 0.1464 - acc: 0.9406 - val_loss: 0.1181 - val_acc: 0.9551\n",
            "Epoch 7/100\n",
            "18/18 [==============================] - 18s 983ms/step - loss: 0.1335 - acc: 0.9485 - val_loss: 0.1116 - val_acc: 0.9567\n",
            "Epoch 8/100\n",
            "18/18 [==============================] - 18s 1s/step - loss: 0.1238 - acc: 0.9528 - val_loss: 0.1164 - val_acc: 0.9556\n",
            "Epoch 9/100\n",
            "18/18 [==============================] - 18s 1s/step - loss: 0.1166 - acc: 0.9545 - val_loss: 0.1043 - val_acc: 0.9583\n",
            "Epoch 10/100\n",
            "18/18 [==============================] - 18s 996ms/step - loss: 0.1221 - acc: 0.9529 - val_loss: 0.0992 - val_acc: 0.9623\n",
            "Epoch 11/100\n",
            "18/18 [==============================] - 18s 998ms/step - loss: 0.1115 - acc: 0.9579 - val_loss: 0.1064 - val_acc: 0.9580\n",
            "Epoch 12/100\n",
            "18/18 [==============================] - 18s 999ms/step - loss: 0.1045 - acc: 0.9588 - val_loss: 0.1035 - val_acc: 0.9589\n",
            "Epoch 13/100\n",
            "18/18 [==============================] - 18s 1s/step - loss: 0.1059 - acc: 0.9607 - val_loss: 0.1033 - val_acc: 0.9596\n",
            "Epoch 14/100\n",
            "18/18 [==============================] - 18s 1s/step - loss: 0.0969 - acc: 0.9639 - val_loss: 0.0917 - val_acc: 0.9663\n",
            "Epoch 15/100\n",
            "18/18 [==============================] - 18s 1s/step - loss: 0.0958 - acc: 0.9650 - val_loss: 0.0890 - val_acc: 0.9681\n",
            "Epoch 16/100\n",
            "18/18 [==============================] - 18s 999ms/step - loss: 0.0946 - acc: 0.9642 - val_loss: 0.0873 - val_acc: 0.9685\n",
            "Epoch 17/100\n",
            "18/18 [==============================] - 18s 1s/step - loss: 0.0898 - acc: 0.9648 - val_loss: 0.0872 - val_acc: 0.9681\n",
            "Epoch 18/100\n",
            "18/18 [==============================] - 18s 1s/step - loss: 0.0898 - acc: 0.9672 - val_loss: 0.0923 - val_acc: 0.9645\n",
            "Epoch 19/100\n",
            "18/18 [==============================] - 18s 1s/step - loss: 0.0844 - acc: 0.9683 - val_loss: 0.0889 - val_acc: 0.9685\n",
            "Epoch 20/100\n",
            "18/18 [==============================] - 18s 999ms/step - loss: 0.0829 - acc: 0.9689 - val_loss: 0.0840 - val_acc: 0.9708\n",
            "Epoch 21/100\n",
            "18/18 [==============================] - 18s 1s/step - loss: 0.0830 - acc: 0.9680 - val_loss: 0.0828 - val_acc: 0.9708\n",
            "Epoch 22/100\n",
            "18/18 [==============================] - 18s 1s/step - loss: 0.0831 - acc: 0.9698 - val_loss: 0.0843 - val_acc: 0.9717\n",
            "Epoch 23/100\n",
            "18/18 [==============================] - 18s 1s/step - loss: 0.0822 - acc: 0.9699 - val_loss: 0.0829 - val_acc: 0.9717\n",
            "Epoch 24/100\n",
            "18/18 [==============================] - 18s 989ms/step - loss: 0.0800 - acc: 0.9694 - val_loss: 0.0844 - val_acc: 0.9705\n",
            "Epoch 25/100\n",
            "18/18 [==============================] - 18s 1s/step - loss: 0.0771 - acc: 0.9712 - val_loss: 0.0852 - val_acc: 0.9699\n",
            "Epoch 26/100\n",
            "18/18 [==============================] - 18s 1s/step - loss: 0.0739 - acc: 0.9723 - val_loss: 0.0825 - val_acc: 0.9714\n",
            "Epoch 27/100\n",
            "18/18 [==============================] - 18s 1000ms/step - loss: 0.0723 - acc: 0.9719 - val_loss: 0.0878 - val_acc: 0.9685\n",
            "Epoch 28/100\n",
            "18/18 [==============================] - 18s 1s/step - loss: 0.0707 - acc: 0.9730 - val_loss: 0.0997 - val_acc: 0.9638\n",
            "Epoch 29/100\n",
            "18/18 [==============================] - 18s 1s/step - loss: 0.0739 - acc: 0.9725 - val_loss: 0.0840 - val_acc: 0.9701\n",
            "Epoch 30/100\n",
            "18/18 [==============================] - 18s 999ms/step - loss: 0.0685 - acc: 0.9752 - val_loss: 0.0826 - val_acc: 0.9714\n",
            "Epoch 31/100\n",
            "18/18 [==============================] - 18s 997ms/step - loss: 0.0665 - acc: 0.9741 - val_loss: 0.0814 - val_acc: 0.9721\n",
            "Epoch 32/100\n",
            "18/18 [==============================] - 18s 1s/step - loss: 0.0695 - acc: 0.9745 - val_loss: 0.0805 - val_acc: 0.9723\n",
            "Epoch 33/100\n",
            "18/18 [==============================] - 18s 994ms/step - loss: 0.0678 - acc: 0.9743 - val_loss: 0.0819 - val_acc: 0.9717\n",
            "Epoch 34/100\n",
            "18/18 [==============================] - 18s 996ms/step - loss: 0.0675 - acc: 0.9741 - val_loss: 0.0958 - val_acc: 0.9663\n",
            "Epoch 35/100\n",
            "18/18 [==============================] - 18s 1s/step - loss: 0.0705 - acc: 0.9733 - val_loss: 0.0792 - val_acc: 0.9734\n",
            "Epoch 36/100\n",
            "18/18 [==============================] - 18s 1s/step - loss: 0.0614 - acc: 0.9771 - val_loss: 0.0799 - val_acc: 0.9743\n",
            "Epoch 37/100\n",
            "18/18 [==============================] - 18s 1s/step - loss: 0.0594 - acc: 0.9767 - val_loss: 0.0865 - val_acc: 0.9694\n",
            "Epoch 38/100\n",
            "18/18 [==============================] - 18s 1s/step - loss: 0.0598 - acc: 0.9777 - val_loss: 0.0781 - val_acc: 0.9737\n",
            "Epoch 39/100\n",
            "18/18 [==============================] - 18s 1s/step - loss: 0.0598 - acc: 0.9762 - val_loss: 0.0798 - val_acc: 0.9732\n",
            "Epoch 40/100\n",
            "18/18 [==============================] - 18s 1s/step - loss: 0.0600 - acc: 0.9777 - val_loss: 0.0790 - val_acc: 0.9739\n",
            "Epoch 41/100\n",
            "18/18 [==============================] - 18s 1s/step - loss: 0.0619 - acc: 0.9757 - val_loss: 0.0804 - val_acc: 0.9728\n",
            "Epoch 42/100\n",
            "18/18 [==============================] - 18s 1s/step - loss: 0.0579 - acc: 0.9775 - val_loss: 0.0832 - val_acc: 0.9710\n",
            "Epoch 43/100\n",
            "18/18 [==============================] - 18s 1s/step - loss: 0.0588 - acc: 0.9789 - val_loss: 0.0784 - val_acc: 0.9730\n",
            "Epoch 44/100\n",
            "18/18 [==============================] - 18s 1s/step - loss: 0.0610 - acc: 0.9776 - val_loss: 0.0805 - val_acc: 0.9725\n",
            "Epoch 45/100\n",
            "18/18 [==============================] - 18s 1s/step - loss: 0.0555 - acc: 0.9789 - val_loss: 0.0803 - val_acc: 0.9728\n",
            "Epoch 46/100\n",
            "18/18 [==============================] - 18s 1s/step - loss: 0.0528 - acc: 0.9810 - val_loss: 0.0827 - val_acc: 0.9719\n",
            "Epoch 47/100\n",
            "18/18 [==============================] - 18s 1s/step - loss: 0.0609 - acc: 0.9772 - val_loss: 0.0813 - val_acc: 0.9717\n",
            "Epoch 48/100\n",
            "18/18 [==============================] - 18s 1s/step - loss: 0.0584 - acc: 0.9780 - val_loss: 0.0797 - val_acc: 0.9728\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzuGtINa_fa_",
        "outputId": "0711afdd-915f-4c1f-ba0b-7a654a012af9"
      },
      "source": [
        "model11.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_12 (Embedding)     (None, None, 50)          500000    \n",
            "_________________________________________________________________\n",
            "gru_2 (GRU)                  (None, None, 30)          7380      \n",
            "_________________________________________________________________\n",
            "gru_3 (GRU)                  (None, None, 50)          12300     \n",
            "_________________________________________________________________\n",
            "gru_4 (GRU)                  (None, 100)               45600     \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 565,381\n",
            "Trainable params: 65,381\n",
            "Non-trainable params: 500,000\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-2JavTrAGTT",
        "outputId": "5e62012b-e4d4-457b-956c-e7b16062b6d2"
      },
      "source": [
        "model11.evaluate(x_test, y_test, verbose = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "300/300 [==============================] - 26s 80ms/step - loss: 0.0779 - acc: 0.9729\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.07786240428686142, 0.9729166626930237]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnynFgcaAS-R",
        "outputId": "c8a83c48-ad43-4d37-cb50-cea3e15709c9"
      },
      "source": [
        "model12 = Sequential()\n",
        "model12.add(Embedding(max_features, 50))\n",
        "model12.add(layers.GRU(30, dropout=0.1,recurrent_dropout=0.5,return_sequences=True))\n",
        "model12.add(layers.GRU(50, activation='relu',dropout=0.1,recurrent_dropout=0.5))\n",
        "model12.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer gru_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXst-ClrAbD0",
        "outputId": "335534b9-0644-4c98-e983-db212a72cb0c"
      },
      "source": [
        "model12.layers[0].set_weights([embedding_matrix])\n",
        "model12.layers[0].trainable = False\n",
        "model12.compile(optimizer='adam',loss='binary_crossentropy', metrics=['acc'])\n",
        "history12 = model12.fit(x_train, y_train,epochs=30,batch_size=1000,validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "18/18 [==============================] - 18s 727ms/step - loss: 0.6866 - acc: 0.5669 - val_loss: 0.5953 - val_acc: 0.8205\n",
            "Epoch 2/30\n",
            "18/18 [==============================] - 12s 646ms/step - loss: 0.5621 - acc: 0.8173 - val_loss: 0.3675 - val_acc: 0.8799\n",
            "Epoch 3/30\n",
            "18/18 [==============================] - 12s 645ms/step - loss: 0.3314 - acc: 0.8796 - val_loss: 0.2236 - val_acc: 0.9121\n",
            "Epoch 4/30\n",
            "18/18 [==============================] - 12s 650ms/step - loss: 0.2198 - acc: 0.9129 - val_loss: 0.1703 - val_acc: 0.9310\n",
            "Epoch 5/30\n",
            "18/18 [==============================] - 12s 667ms/step - loss: 0.1795 - acc: 0.9303 - val_loss: 0.1481 - val_acc: 0.9433\n",
            "Epoch 6/30\n",
            "18/18 [==============================] - 12s 643ms/step - loss: 0.1644 - acc: 0.9350 - val_loss: 0.1349 - val_acc: 0.9473\n",
            "Epoch 7/30\n",
            "18/18 [==============================] - 12s 649ms/step - loss: 0.1426 - acc: 0.9446 - val_loss: 0.1253 - val_acc: 0.9513\n",
            "Epoch 8/30\n",
            "18/18 [==============================] - 12s 655ms/step - loss: 0.1421 - acc: 0.9448 - val_loss: 0.1185 - val_acc: 0.9549\n",
            "Epoch 9/30\n",
            "18/18 [==============================] - 11s 639ms/step - loss: 0.1335 - acc: 0.9476 - val_loss: 0.1194 - val_acc: 0.9545\n",
            "Epoch 10/30\n",
            "18/18 [==============================] - 12s 641ms/step - loss: 0.1247 - acc: 0.9525 - val_loss: 0.1095 - val_acc: 0.9576\n",
            "Epoch 11/30\n",
            "18/18 [==============================] - 11s 631ms/step - loss: 0.1262 - acc: 0.9520 - val_loss: 0.1060 - val_acc: 0.9587\n",
            "Epoch 12/30\n",
            "18/18 [==============================] - 12s 637ms/step - loss: 0.1161 - acc: 0.9578 - val_loss: 0.1038 - val_acc: 0.9600\n",
            "Epoch 13/30\n",
            "18/18 [==============================] - 12s 655ms/step - loss: 0.1085 - acc: 0.9606 - val_loss: 0.0994 - val_acc: 0.9636\n",
            "Epoch 14/30\n",
            "18/18 [==============================] - 12s 650ms/step - loss: 0.1112 - acc: 0.9557 - val_loss: 0.0972 - val_acc: 0.9632\n",
            "Epoch 15/30\n",
            "18/18 [==============================] - 12s 645ms/step - loss: 0.1033 - acc: 0.9613 - val_loss: 0.0988 - val_acc: 0.9618\n",
            "Epoch 16/30\n",
            "18/18 [==============================] - 12s 646ms/step - loss: 0.1010 - acc: 0.9626 - val_loss: 0.0952 - val_acc: 0.9636\n",
            "Epoch 17/30\n",
            "18/18 [==============================] - 12s 646ms/step - loss: 0.0992 - acc: 0.9640 - val_loss: 0.0923 - val_acc: 0.9654\n",
            "Epoch 18/30\n",
            "18/18 [==============================] - 11s 638ms/step - loss: 0.1014 - acc: 0.9639 - val_loss: 0.0913 - val_acc: 0.9654\n",
            "Epoch 19/30\n",
            "18/18 [==============================] - 12s 649ms/step - loss: 0.0981 - acc: 0.9642 - val_loss: 0.0893 - val_acc: 0.9661\n",
            "Epoch 20/30\n",
            "18/18 [==============================] - 11s 640ms/step - loss: 0.0923 - acc: 0.9660 - val_loss: 0.0885 - val_acc: 0.9665\n",
            "Epoch 21/30\n",
            "18/18 [==============================] - 12s 649ms/step - loss: 0.0888 - acc: 0.9668 - val_loss: 0.0888 - val_acc: 0.9683\n",
            "Epoch 22/30\n",
            "18/18 [==============================] - 12s 643ms/step - loss: 0.0927 - acc: 0.9662 - val_loss: 0.0880 - val_acc: 0.9683\n",
            "Epoch 23/30\n",
            "18/18 [==============================] - 12s 641ms/step - loss: 0.0833 - acc: 0.9682 - val_loss: 0.0857 - val_acc: 0.9683\n",
            "Epoch 24/30\n",
            "18/18 [==============================] - 12s 646ms/step - loss: 0.0868 - acc: 0.9684 - val_loss: 0.0846 - val_acc: 0.9694\n",
            "Epoch 25/30\n",
            "18/18 [==============================] - 12s 651ms/step - loss: 0.0864 - acc: 0.9689 - val_loss: 0.0868 - val_acc: 0.9681\n",
            "Epoch 26/30\n",
            "18/18 [==============================] - 12s 639ms/step - loss: 0.0775 - acc: 0.9701 - val_loss: 0.0857 - val_acc: 0.9688\n",
            "Epoch 27/30\n",
            "18/18 [==============================] - 12s 644ms/step - loss: 0.0808 - acc: 0.9698 - val_loss: 0.0828 - val_acc: 0.9696\n",
            "Epoch 28/30\n",
            "18/18 [==============================] - 11s 635ms/step - loss: 0.0794 - acc: 0.9703 - val_loss: 0.0872 - val_acc: 0.9683\n",
            "Epoch 29/30\n",
            "18/18 [==============================] - 12s 648ms/step - loss: 0.0747 - acc: 0.9729 - val_loss: 0.0825 - val_acc: 0.9699\n",
            "Epoch 30/30\n",
            "18/18 [==============================] - 12s 656ms/step - loss: 0.0752 - acc: 0.9728 - val_loss: 0.0846 - val_acc: 0.9696\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRjGciMcBj4R",
        "outputId": "79f550c0-c154-41f3-dc3f-378640235c0a"
      },
      "source": [
        "predictions = model11.evaluate(x_test, y_test, verbose = True)\n",
        "predictions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "300/300 [==============================] - 24s 79ms/step - loss: 0.0779 - acc: 0.9729\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.07786240428686142, 0.9729166626930237]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfhWxetBDdnV",
        "outputId": "9ca061c4-9849-487d-afe6-42f00a402bba"
      },
      "source": [
        "predictions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.07786240428686142, 0.9729166626930237]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdZGNoWdDftF",
        "outputId": "7307c0cd-eb40-4b13-d50c-54326f19ab56"
      },
      "source": [
        "predictions2 = model11.predict_classes(x_test)\n",
        "predictions2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [0],\n",
              "       [1],\n",
              "       ...,\n",
              "       [0],\n",
              "       [0],\n",
              "       [1]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        },
        "id": "2aFObT2ZEHFA",
        "outputId": "3e18f877-cbda-49bf-ae39-d10a2b18bd5c"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "print(confusion_matrix(y_test, predictions2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-ebd7431360e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'y_test' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6R89kRUHE7ko",
        "outputId": "a363d08f-5a9a-46b1-a9af-e97c0dd98f29"
      },
      "source": [
        "y_test.sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4771"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0aDvBensdw7",
        "outputId": "a4aafecf-ab08-4105-b99c-23df238d4159"
      },
      "source": [
        "predictions = model.predict_classes(x_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1Sn0wsjs8w-",
        "outputId": "4c95b2f6-fa61-4ad4-daa5-7d8e1b4eb81e"
      },
      "source": [
        "print(confusion_matrix(y_test, predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[4576  226]\n",
            " [ 381 4417]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3H4N0eiBs86W",
        "outputId": "acf22077-5707-4890-da6a-dc92e56f0400"
      },
      "source": [
        "confusion_matrix(y_test, predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4576,  226],\n",
              "       [ 381, 4417]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UiFbsB-s9BK"
      },
      "source": [
        "predictions2 = np.argmax(model.predict(x_test), axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bBl_Zrsw4mg",
        "outputId": "b29f8881-81dc-4591-eed0-76bb45ea62d8"
      },
      "source": [
        "confusion_matrix(y_test, predictions2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4802,    0],\n",
              "       [4798,    0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5Jyz1MjyFdY",
        "outputId": "34eaee21-74dd-4010-e939-aa152a199d4c"
      },
      "source": [
        "print(y_test)\n",
        "print(predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 1 ... 1 1 1]\n",
            "[[0]\n",
            " [1]\n",
            " [0]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQmM1VQAyLV8",
        "outputId": "57e16813-9bc1-4a75-84c1-24a016611c01"
      },
      "source": [
        "print(confusion_matrix(y_test, predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[4576  226]\n",
            " [ 381 4417]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "455w2Bb8ySI_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90a2dee6-8779-4415-8ceb-a2abf1bef7de"
      },
      "source": [
        "print(confusion_matrix(predictions, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[4576  381]\n",
            " [ 226 4417]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}